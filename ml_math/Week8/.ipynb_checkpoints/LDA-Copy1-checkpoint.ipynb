{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import random\n",
    "import bisect\n",
    "import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_dict = []\n",
    "#location of your English dictionary\n",
    "dict_file = open(\"dictionary.txt\",'r')\n",
    "for line in dict_file:\n",
    "    #I assume your dictionary's words are separated by whitespace,\n",
    "    #but it it's commas you can do split(',')\n",
    "    items = line.split()\n",
    "    for word in items:\n",
    "        eng_dict.append(word)\n",
    "\n",
    "#word_index serves as a two-way lookup table: given a word, return its index,\n",
    "#and vice-versa. Also has key \"n_words\" which gives number of words in\n",
    "#vocabulary.\n",
    "word_index = {\"n_words\":0}\n",
    "#The coefficients alpha and beta are derived from the multinomial distribution\n",
    "#assumed by the model. alpha=0.1 and beta=0.0002 are generally good.\n",
    "#The lower alpha, the fewer topics per document\n",
    "#alpha should be low but nonzero so that words can group by document as well.\n",
    "alpha = 0.1\n",
    "#The lower beta, more extreme each topic's word frequencies\n",
    "beta = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yeah',\n",
       " 'explosions',\n",
       " 'possibly',\n",
       " 'sure',\n",
       " 'simply',\n",
       " 'Unfortunate',\n",
       " 'get',\n",
       " 'unexpected',\n",
       " 'hella',\n",
       " 'picture']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_dict[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fnames():\n",
    "    #your function for creating a list of files to use\n",
    "    names = []\n",
    "    dir = \"data/\"\n",
    "    exts = [\"txt\"]\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for f in files:\n",
    "            items = f.split('.')\n",
    "            if len(items) > 1 and items[1] in exts:\n",
    "                names.append(root+\"/\"+f)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data//doc0.txt',\n",
       " 'data//doc1.txt',\n",
       " 'data//doc10.txt',\n",
       " 'data//doc100.txt',\n",
       " 'data//doc1000.txt',\n",
       " 'data//doc1001.txt',\n",
       " 'data//doc1002.txt',\n",
       " 'data//doc1003.txt',\n",
       " 'data//doc1004.txt',\n",
       " 'data//doc1005.txt',\n",
       " 'data//doc1006.txt',\n",
       " 'data//doc1007.txt',\n",
       " 'data//doc1008.txt',\n",
       " 'data//doc1009.txt',\n",
       " 'data//doc101.txt',\n",
       " 'data//doc1010.txt',\n",
       " 'data//doc1011.txt',\n",
       " 'data//doc1012.txt',\n",
       " 'data//doc1013.txt',\n",
       " 'data//doc1014.txt',\n",
       " 'data//doc1015.txt',\n",
       " 'data//doc1016.txt',\n",
       " 'data//doc1017.txt',\n",
       " 'data//doc1018.txt',\n",
       " 'data//doc1019.txt',\n",
       " 'data//doc102.txt',\n",
       " 'data//doc1020.txt',\n",
       " 'data//doc1021.txt',\n",
       " 'data//doc1022.txt',\n",
       " 'data//doc1023.txt',\n",
       " 'data//doc1024.txt',\n",
       " 'data//doc1025.txt',\n",
       " 'data//doc1026.txt',\n",
       " 'data//doc1027.txt',\n",
       " 'data//doc1028.txt',\n",
       " 'data//doc1029.txt',\n",
       " 'data//doc103.txt',\n",
       " 'data//doc1030.txt',\n",
       " 'data//doc1031.txt',\n",
       " 'data//doc1032.txt',\n",
       " 'data//doc1033.txt',\n",
       " 'data//doc1034.txt',\n",
       " 'data//doc1035.txt',\n",
       " 'data//doc1036.txt',\n",
       " 'data//doc1037.txt',\n",
       " 'data//doc1038.txt',\n",
       " 'data//doc1039.txt',\n",
       " 'data//doc104.txt',\n",
       " 'data//doc1040.txt',\n",
       " 'data//doc1041.txt',\n",
       " 'data//doc1042.txt',\n",
       " 'data//doc1043.txt',\n",
       " 'data//doc1044.txt',\n",
       " 'data//doc1045.txt',\n",
       " 'data//doc1046.txt',\n",
       " 'data//doc1047.txt',\n",
       " 'data//doc1048.txt',\n",
       " 'data//doc1049.txt',\n",
       " 'data//doc105.txt',\n",
       " 'data//doc1050.txt',\n",
       " 'data//doc1051.txt',\n",
       " 'data//doc1052.txt',\n",
       " 'data//doc1053.txt',\n",
       " 'data//doc1054.txt',\n",
       " 'data//doc1055.txt',\n",
       " 'data//doc1056.txt',\n",
       " 'data//doc1057.txt',\n",
       " 'data//doc1058.txt',\n",
       " 'data//doc1059.txt',\n",
       " 'data//doc106.txt',\n",
       " 'data//doc1060.txt',\n",
       " 'data//doc1061.txt',\n",
       " 'data//doc1062.txt',\n",
       " 'data//doc1063.txt',\n",
       " 'data//doc1064.txt',\n",
       " 'data//doc1065.txt',\n",
       " 'data//doc1066.txt',\n",
       " 'data//doc1067.txt',\n",
       " 'data//doc1068.txt',\n",
       " 'data//doc1069.txt',\n",
       " 'data//doc107.txt',\n",
       " 'data//doc1070.txt',\n",
       " 'data//doc1071.txt',\n",
       " 'data//doc1072.txt',\n",
       " 'data//doc1073.txt',\n",
       " 'data//doc1074.txt',\n",
       " 'data//doc1075.txt',\n",
       " 'data//doc1076.txt',\n",
       " 'data//doc1077.txt',\n",
       " 'data//doc1078.txt',\n",
       " 'data//doc1079.txt',\n",
       " 'data//doc108.txt',\n",
       " 'data//doc1080.txt',\n",
       " 'data//doc1081.txt',\n",
       " 'data//doc1082.txt',\n",
       " 'data//doc1083.txt',\n",
       " 'data//doc1084.txt',\n",
       " 'data//doc1085.txt',\n",
       " 'data//doc1086.txt',\n",
       " 'data//doc1087.txt',\n",
       " 'data//doc1088.txt',\n",
       " 'data//doc1089.txt',\n",
       " 'data//doc109.txt',\n",
       " 'data//doc1090.txt',\n",
       " 'data//doc1091.txt',\n",
       " 'data//doc1092.txt',\n",
       " 'data//doc1093.txt',\n",
       " 'data//doc1094.txt',\n",
       " 'data//doc1095.txt',\n",
       " 'data//doc1096.txt',\n",
       " 'data//doc1097.txt',\n",
       " 'data//doc1098.txt',\n",
       " 'data//doc1099.txt',\n",
       " 'data//doc11.txt',\n",
       " 'data//doc110.txt',\n",
       " 'data//doc1100.txt',\n",
       " 'data//doc1101.txt',\n",
       " 'data//doc1102.txt',\n",
       " 'data//doc1103.txt',\n",
       " 'data//doc1104.txt',\n",
       " 'data//doc1105.txt',\n",
       " 'data//doc1106.txt',\n",
       " 'data//doc1107.txt',\n",
       " 'data//doc1108.txt',\n",
       " 'data//doc1109.txt',\n",
       " 'data//doc111.txt',\n",
       " 'data//doc1110.txt',\n",
       " 'data//doc1111.txt',\n",
       " 'data//doc1112.txt',\n",
       " 'data//doc1113.txt',\n",
       " 'data//doc1114.txt',\n",
       " 'data//doc1115.txt',\n",
       " 'data//doc1116.txt',\n",
       " 'data//doc1117.txt',\n",
       " 'data//doc1118.txt',\n",
       " 'data//doc1119.txt',\n",
       " 'data//doc112.txt',\n",
       " 'data//doc1120.txt',\n",
       " 'data//doc1121.txt',\n",
       " 'data//doc1122.txt',\n",
       " 'data//doc1123.txt',\n",
       " 'data//doc1124.txt',\n",
       " 'data//doc1125.txt',\n",
       " 'data//doc1126.txt',\n",
       " 'data//doc1127.txt',\n",
       " 'data//doc1128.txt',\n",
       " 'data//doc1129.txt',\n",
       " 'data//doc113.txt',\n",
       " 'data//doc1130.txt',\n",
       " 'data//doc1131.txt',\n",
       " 'data//doc1132.txt',\n",
       " 'data//doc1133.txt',\n",
       " 'data//doc1134.txt',\n",
       " 'data//doc1135.txt',\n",
       " 'data//doc1136.txt',\n",
       " 'data//doc1137.txt',\n",
       " 'data//doc1138.txt',\n",
       " 'data//doc1139.txt',\n",
       " 'data//doc114.txt',\n",
       " 'data//doc1140.txt',\n",
       " 'data//doc1141.txt',\n",
       " 'data//doc1142.txt',\n",
       " 'data//doc1143.txt',\n",
       " 'data//doc1144.txt',\n",
       " 'data//doc1145.txt',\n",
       " 'data//doc1146.txt',\n",
       " 'data//doc1147.txt',\n",
       " 'data//doc1148.txt',\n",
       " 'data//doc1149.txt',\n",
       " 'data//doc115.txt',\n",
       " 'data//doc1150.txt',\n",
       " 'data//doc1151.txt',\n",
       " 'data//doc1152.txt',\n",
       " 'data//doc1153.txt',\n",
       " 'data//doc1154.txt',\n",
       " 'data//doc1155.txt',\n",
       " 'data//doc1156.txt',\n",
       " 'data//doc1157.txt',\n",
       " 'data//doc1158.txt',\n",
       " 'data//doc1159.txt',\n",
       " 'data//doc116.txt',\n",
       " 'data//doc1160.txt',\n",
       " 'data//doc1161.txt',\n",
       " 'data//doc1162.txt',\n",
       " 'data//doc1163.txt',\n",
       " 'data//doc1164.txt',\n",
       " 'data//doc1165.txt',\n",
       " 'data//doc1166.txt',\n",
       " 'data//doc1167.txt',\n",
       " 'data//doc1168.txt',\n",
       " 'data//doc1169.txt',\n",
       " 'data//doc117.txt',\n",
       " 'data//doc1170.txt',\n",
       " 'data//doc1171.txt',\n",
       " 'data//doc1172.txt',\n",
       " 'data//doc1173.txt',\n",
       " 'data//doc1174.txt',\n",
       " 'data//doc1175.txt',\n",
       " 'data//doc1176.txt',\n",
       " 'data//doc1177.txt',\n",
       " 'data//doc1178.txt',\n",
       " 'data//doc1179.txt',\n",
       " 'data//doc118.txt',\n",
       " 'data//doc1180.txt',\n",
       " 'data//doc1181.txt',\n",
       " 'data//doc1182.txt',\n",
       " 'data//doc1183.txt',\n",
       " 'data//doc1184.txt',\n",
       " 'data//doc1185.txt',\n",
       " 'data//doc1186.txt',\n",
       " 'data//doc1187.txt',\n",
       " 'data//doc1188.txt',\n",
       " 'data//doc1189.txt',\n",
       " 'data//doc119.txt',\n",
       " 'data//doc1190.txt',\n",
       " 'data//doc1191.txt',\n",
       " 'data//doc1192.txt',\n",
       " 'data//doc1193.txt',\n",
       " 'data//doc1194.txt',\n",
       " 'data//doc1195.txt',\n",
       " 'data//doc1196.txt',\n",
       " 'data//doc1197.txt',\n",
       " 'data//doc1198.txt',\n",
       " 'data//doc1199.txt',\n",
       " 'data//doc12.txt',\n",
       " 'data//doc120.txt',\n",
       " 'data//doc1200.txt',\n",
       " 'data//doc1201.txt',\n",
       " 'data//doc1202.txt',\n",
       " 'data//doc1203.txt',\n",
       " 'data//doc1204.txt',\n",
       " 'data//doc1205.txt',\n",
       " 'data//doc1206.txt',\n",
       " 'data//doc1207.txt',\n",
       " 'data//doc1208.txt',\n",
       " 'data//doc1209.txt',\n",
       " 'data//doc121.txt',\n",
       " 'data//doc1210.txt',\n",
       " 'data//doc1211.txt',\n",
       " 'data//doc1212.txt',\n",
       " 'data//doc1213.txt',\n",
       " 'data//doc1214.txt',\n",
       " 'data//doc1215.txt',\n",
       " 'data//doc1216.txt',\n",
       " 'data//doc1217.txt',\n",
       " 'data//doc1218.txt',\n",
       " 'data//doc1219.txt',\n",
       " 'data//doc122.txt',\n",
       " 'data//doc1220.txt',\n",
       " 'data//doc1221.txt',\n",
       " 'data//doc1222.txt',\n",
       " 'data//doc1223.txt',\n",
       " 'data//doc1224.txt',\n",
       " 'data//doc1225.txt',\n",
       " 'data//doc1226.txt',\n",
       " 'data//doc1227.txt',\n",
       " 'data//doc1228.txt',\n",
       " 'data//doc1229.txt',\n",
       " 'data//doc123.txt',\n",
       " 'data//doc1230.txt',\n",
       " 'data//doc1231.txt',\n",
       " 'data//doc1232.txt',\n",
       " 'data//doc1233.txt',\n",
       " 'data//doc1234.txt',\n",
       " 'data//doc1235.txt',\n",
       " 'data//doc1236.txt',\n",
       " 'data//doc1237.txt',\n",
       " 'data//doc1238.txt',\n",
       " 'data//doc1239.txt',\n",
       " 'data//doc124.txt',\n",
       " 'data//doc1240.txt',\n",
       " 'data//doc1241.txt',\n",
       " 'data//doc1242.txt',\n",
       " 'data//doc1243.txt',\n",
       " 'data//doc1244.txt',\n",
       " 'data//doc1245.txt',\n",
       " 'data//doc1246.txt',\n",
       " 'data//doc1247.txt',\n",
       " 'data//doc1248.txt',\n",
       " 'data//doc1249.txt',\n",
       " 'data//doc125.txt',\n",
       " 'data//doc1250.txt',\n",
       " 'data//doc1251.txt',\n",
       " 'data//doc1252.txt',\n",
       " 'data//doc1253.txt',\n",
       " 'data//doc1254.txt',\n",
       " 'data//doc1255.txt',\n",
       " 'data//doc1256.txt',\n",
       " 'data//doc1257.txt',\n",
       " 'data//doc1258.txt',\n",
       " 'data//doc1259.txt',\n",
       " 'data//doc126.txt',\n",
       " 'data//doc1260.txt',\n",
       " 'data//doc1261.txt',\n",
       " 'data//doc1262.txt',\n",
       " 'data//doc1263.txt',\n",
       " 'data//doc1264.txt',\n",
       " 'data//doc1265.txt',\n",
       " 'data//doc1266.txt',\n",
       " 'data//doc1267.txt',\n",
       " 'data//doc1268.txt',\n",
       " 'data//doc1269.txt',\n",
       " 'data//doc127.txt',\n",
       " 'data//doc1270.txt',\n",
       " 'data//doc1271.txt',\n",
       " 'data//doc1272.txt',\n",
       " 'data//doc1273.txt',\n",
       " 'data//doc1274.txt',\n",
       " 'data//doc1275.txt',\n",
       " 'data//doc1276.txt',\n",
       " 'data//doc1277.txt',\n",
       " 'data//doc1278.txt',\n",
       " 'data//doc1279.txt',\n",
       " 'data//doc128.txt',\n",
       " 'data//doc1280.txt',\n",
       " 'data//doc1281.txt',\n",
       " 'data//doc1282.txt',\n",
       " 'data//doc1283.txt',\n",
       " 'data//doc1284.txt',\n",
       " 'data//doc1285.txt',\n",
       " 'data//doc1286.txt',\n",
       " 'data//doc1287.txt',\n",
       " 'data//doc1288.txt',\n",
       " 'data//doc1289.txt',\n",
       " 'data//doc129.txt',\n",
       " 'data//doc1290.txt',\n",
       " 'data//doc1291.txt',\n",
       " 'data//doc1292.txt',\n",
       " 'data//doc1293.txt',\n",
       " 'data//doc1294.txt',\n",
       " 'data//doc1295.txt',\n",
       " 'data//doc1296.txt',\n",
       " 'data//doc1297.txt',\n",
       " 'data//doc1298.txt',\n",
       " 'data//doc1299.txt',\n",
       " 'data//doc13.txt',\n",
       " 'data//doc130.txt',\n",
       " 'data//doc1300.txt',\n",
       " 'data//doc1301.txt',\n",
       " 'data//doc1302.txt',\n",
       " 'data//doc1303.txt',\n",
       " 'data//doc1304.txt',\n",
       " 'data//doc1305.txt',\n",
       " 'data//doc1306.txt',\n",
       " 'data//doc1307.txt',\n",
       " 'data//doc1308.txt',\n",
       " 'data//doc1309.txt',\n",
       " 'data//doc131.txt',\n",
       " 'data//doc1310.txt',\n",
       " 'data//doc1311.txt',\n",
       " 'data//doc1312.txt',\n",
       " 'data//doc1313.txt',\n",
       " 'data//doc1314.txt',\n",
       " 'data//doc1315.txt',\n",
       " 'data//doc1316.txt',\n",
       " 'data//doc1317.txt',\n",
       " 'data//doc1318.txt',\n",
       " 'data//doc1319.txt',\n",
       " 'data//doc132.txt',\n",
       " 'data//doc1320.txt',\n",
       " 'data//doc1321.txt',\n",
       " 'data//doc1322.txt',\n",
       " 'data//doc1323.txt',\n",
       " 'data//doc1324.txt',\n",
       " 'data//doc1325.txt',\n",
       " 'data//doc1326.txt',\n",
       " 'data//doc1327.txt',\n",
       " 'data//doc1328.txt',\n",
       " 'data//doc1329.txt',\n",
       " 'data//doc133.txt',\n",
       " 'data//doc1330.txt',\n",
       " 'data//doc1331.txt',\n",
       " 'data//doc1332.txt',\n",
       " 'data//doc1333.txt',\n",
       " 'data//doc1334.txt',\n",
       " 'data//doc1335.txt',\n",
       " 'data//doc1336.txt',\n",
       " 'data//doc1337.txt',\n",
       " 'data//doc1338.txt',\n",
       " 'data//doc1339.txt',\n",
       " 'data//doc134.txt',\n",
       " 'data//doc1340.txt',\n",
       " 'data//doc1341.txt',\n",
       " 'data//doc1342.txt',\n",
       " 'data//doc1343.txt',\n",
       " 'data//doc1344.txt',\n",
       " 'data//doc1345.txt',\n",
       " 'data//doc1346.txt',\n",
       " 'data//doc1347.txt',\n",
       " 'data//doc1348.txt',\n",
       " 'data//doc1349.txt',\n",
       " 'data//doc135.txt',\n",
       " 'data//doc1350.txt',\n",
       " 'data//doc1351.txt',\n",
       " 'data//doc1352.txt',\n",
       " 'data//doc1353.txt',\n",
       " 'data//doc1354.txt',\n",
       " 'data//doc1355.txt',\n",
       " 'data//doc1356.txt',\n",
       " 'data//doc1357.txt',\n",
       " 'data//doc1358.txt',\n",
       " 'data//doc1359.txt',\n",
       " 'data//doc136.txt',\n",
       " 'data//doc1360.txt',\n",
       " 'data//doc1361.txt',\n",
       " 'data//doc1362.txt',\n",
       " 'data//doc1363.txt',\n",
       " 'data//doc1364.txt',\n",
       " 'data//doc1365.txt',\n",
       " 'data//doc1366.txt',\n",
       " 'data//doc1367.txt',\n",
       " 'data//doc1368.txt',\n",
       " 'data//doc1369.txt',\n",
       " 'data//doc137.txt',\n",
       " 'data//doc1370.txt',\n",
       " 'data//doc1371.txt',\n",
       " 'data//doc1372.txt',\n",
       " 'data//doc1373.txt',\n",
       " 'data//doc1374.txt',\n",
       " 'data//doc1375.txt',\n",
       " 'data//doc1376.txt',\n",
       " 'data//doc1377.txt',\n",
       " 'data//doc1378.txt',\n",
       " 'data//doc1379.txt',\n",
       " 'data//doc138.txt',\n",
       " 'data//doc1380.txt',\n",
       " 'data//doc1381.txt',\n",
       " 'data//doc1382.txt',\n",
       " 'data//doc1383.txt',\n",
       " 'data//doc1384.txt',\n",
       " 'data//doc1385.txt',\n",
       " 'data//doc1386.txt',\n",
       " 'data//doc1387.txt',\n",
       " 'data//doc1388.txt',\n",
       " 'data//doc1389.txt',\n",
       " 'data//doc139.txt',\n",
       " 'data//doc1390.txt',\n",
       " 'data//doc1391.txt',\n",
       " 'data//doc1392.txt',\n",
       " 'data//doc1393.txt',\n",
       " 'data//doc1394.txt',\n",
       " 'data//doc1395.txt',\n",
       " 'data//doc1396.txt',\n",
       " 'data//doc1397.txt',\n",
       " 'data//doc1398.txt',\n",
       " 'data//doc1399.txt',\n",
       " 'data//doc14.txt',\n",
       " 'data//doc140.txt',\n",
       " 'data//doc1400.txt',\n",
       " 'data//doc1401.txt',\n",
       " 'data//doc1402.txt',\n",
       " 'data//doc1403.txt',\n",
       " 'data//doc1404.txt',\n",
       " 'data//doc1405.txt',\n",
       " 'data//doc1406.txt',\n",
       " 'data//doc1407.txt',\n",
       " 'data//doc1408.txt',\n",
       " 'data//doc1409.txt',\n",
       " 'data//doc141.txt',\n",
       " 'data//doc1410.txt',\n",
       " 'data//doc1411.txt',\n",
       " 'data//doc1412.txt',\n",
       " 'data//doc1413.txt',\n",
       " 'data//doc1414.txt',\n",
       " 'data//doc1415.txt',\n",
       " 'data//doc1416.txt',\n",
       " 'data//doc1417.txt',\n",
       " 'data//doc1418.txt',\n",
       " 'data//doc1419.txt',\n",
       " 'data//doc142.txt',\n",
       " 'data//doc1420.txt',\n",
       " 'data//doc1421.txt',\n",
       " 'data//doc1422.txt',\n",
       " 'data//doc1423.txt',\n",
       " 'data//doc1424.txt',\n",
       " 'data//doc1425.txt',\n",
       " 'data//doc1426.txt',\n",
       " 'data//doc1427.txt',\n",
       " 'data//doc1428.txt',\n",
       " 'data//doc1429.txt',\n",
       " 'data//doc143.txt',\n",
       " 'data//doc1430.txt',\n",
       " 'data//doc1431.txt',\n",
       " 'data//doc1432.txt',\n",
       " 'data//doc1433.txt',\n",
       " 'data//doc1434.txt',\n",
       " 'data//doc1435.txt',\n",
       " 'data//doc1436.txt',\n",
       " 'data//doc1437.txt',\n",
       " 'data//doc1438.txt',\n",
       " 'data//doc1439.txt',\n",
       " 'data//doc144.txt',\n",
       " 'data//doc1440.txt',\n",
       " 'data//doc1441.txt',\n",
       " 'data//doc1442.txt',\n",
       " 'data//doc1443.txt',\n",
       " 'data//doc1444.txt',\n",
       " 'data//doc1445.txt',\n",
       " 'data//doc1446.txt',\n",
       " 'data//doc1447.txt',\n",
       " 'data//doc1448.txt',\n",
       " 'data//doc1449.txt',\n",
       " 'data//doc145.txt',\n",
       " 'data//doc1450.txt',\n",
       " 'data//doc1451.txt',\n",
       " 'data//doc1452.txt',\n",
       " 'data//doc1453.txt',\n",
       " 'data//doc1454.txt',\n",
       " 'data//doc1455.txt',\n",
       " 'data//doc1456.txt',\n",
       " 'data//doc1457.txt',\n",
       " 'data//doc1458.txt',\n",
       " 'data//doc1459.txt',\n",
       " 'data//doc146.txt',\n",
       " 'data//doc1460.txt',\n",
       " 'data//doc1461.txt',\n",
       " 'data//doc1462.txt',\n",
       " 'data//doc1463.txt',\n",
       " 'data//doc1464.txt',\n",
       " 'data//doc1465.txt',\n",
       " 'data//doc1466.txt',\n",
       " 'data//doc1467.txt',\n",
       " 'data//doc1468.txt',\n",
       " 'data//doc1469.txt',\n",
       " 'data//doc147.txt',\n",
       " 'data//doc1470.txt',\n",
       " 'data//doc1471.txt',\n",
       " 'data//doc1472.txt',\n",
       " 'data//doc1473.txt',\n",
       " 'data//doc1474.txt',\n",
       " 'data//doc1475.txt',\n",
       " 'data//doc1476.txt',\n",
       " 'data//doc1477.txt',\n",
       " 'data//doc1478.txt',\n",
       " 'data//doc1479.txt',\n",
       " 'data//doc148.txt',\n",
       " 'data//doc1480.txt',\n",
       " 'data//doc1481.txt',\n",
       " 'data//doc1482.txt',\n",
       " 'data//doc1483.txt',\n",
       " 'data//doc1484.txt',\n",
       " 'data//doc1485.txt',\n",
       " 'data//doc1486.txt',\n",
       " 'data//doc1487.txt',\n",
       " 'data//doc1488.txt',\n",
       " 'data//doc1489.txt',\n",
       " 'data//doc149.txt',\n",
       " 'data//doc1490.txt',\n",
       " 'data//doc1491.txt',\n",
       " 'data//doc1492.txt',\n",
       " 'data//doc1493.txt',\n",
       " 'data//doc1494.txt',\n",
       " 'data//doc1495.txt',\n",
       " 'data//doc1496.txt',\n",
       " 'data//doc1497.txt',\n",
       " 'data//doc1498.txt',\n",
       " 'data//doc1499.txt',\n",
       " 'data//doc15.txt',\n",
       " 'data//doc150.txt',\n",
       " 'data//doc1500.txt',\n",
       " 'data//doc1501.txt',\n",
       " 'data//doc1502.txt',\n",
       " 'data//doc1503.txt',\n",
       " 'data//doc1504.txt',\n",
       " 'data//doc1505.txt',\n",
       " 'data//doc1506.txt',\n",
       " 'data//doc1507.txt',\n",
       " 'data//doc1508.txt',\n",
       " 'data//doc1509.txt',\n",
       " 'data//doc151.txt',\n",
       " 'data//doc1510.txt',\n",
       " 'data//doc1511.txt',\n",
       " 'data//doc1512.txt',\n",
       " 'data//doc1513.txt',\n",
       " 'data//doc1514.txt',\n",
       " 'data//doc1515.txt',\n",
       " 'data//doc1516.txt',\n",
       " 'data//doc1517.txt',\n",
       " 'data//doc1518.txt',\n",
       " 'data//doc1519.txt',\n",
       " 'data//doc152.txt',\n",
       " 'data//doc1520.txt',\n",
       " 'data//doc1521.txt',\n",
       " 'data//doc1522.txt',\n",
       " 'data//doc1523.txt',\n",
       " 'data//doc1524.txt',\n",
       " 'data//doc1525.txt',\n",
       " 'data//doc1526.txt',\n",
       " 'data//doc1527.txt',\n",
       " 'data//doc1528.txt',\n",
       " 'data//doc1529.txt',\n",
       " 'data//doc153.txt',\n",
       " 'data//doc1530.txt',\n",
       " 'data//doc1531.txt',\n",
       " 'data//doc1532.txt',\n",
       " 'data//doc1533.txt',\n",
       " 'data//doc1534.txt',\n",
       " 'data//doc1535.txt',\n",
       " 'data//doc1536.txt',\n",
       " 'data//doc1537.txt',\n",
       " 'data//doc1538.txt',\n",
       " 'data//doc1539.txt',\n",
       " 'data//doc154.txt',\n",
       " 'data//doc1540.txt',\n",
       " 'data//doc1541.txt',\n",
       " 'data//doc1542.txt',\n",
       " 'data//doc1543.txt',\n",
       " 'data//doc1544.txt',\n",
       " 'data//doc1545.txt',\n",
       " 'data//doc1546.txt',\n",
       " 'data//doc1547.txt',\n",
       " 'data//doc1548.txt',\n",
       " 'data//doc1549.txt',\n",
       " 'data//doc155.txt',\n",
       " 'data//doc1550.txt',\n",
       " 'data//doc1551.txt',\n",
       " 'data//doc1552.txt',\n",
       " 'data//doc1553.txt',\n",
       " 'data//doc1554.txt',\n",
       " 'data//doc1555.txt',\n",
       " 'data//doc1556.txt',\n",
       " 'data//doc1557.txt',\n",
       " 'data//doc1558.txt',\n",
       " 'data//doc1559.txt',\n",
       " 'data//doc156.txt',\n",
       " 'data//doc1560.txt',\n",
       " 'data//doc1561.txt',\n",
       " 'data//doc1562.txt',\n",
       " 'data//doc1563.txt',\n",
       " 'data//doc1564.txt',\n",
       " 'data//doc1565.txt',\n",
       " 'data//doc1566.txt',\n",
       " 'data//doc1567.txt',\n",
       " 'data//doc1568.txt',\n",
       " 'data//doc1569.txt',\n",
       " 'data//doc157.txt',\n",
       " 'data//doc1570.txt',\n",
       " 'data//doc1571.txt',\n",
       " 'data//doc1572.txt',\n",
       " 'data//doc1573.txt',\n",
       " 'data//doc1574.txt',\n",
       " 'data//doc1575.txt',\n",
       " 'data//doc1576.txt',\n",
       " 'data//doc1577.txt',\n",
       " 'data//doc1578.txt',\n",
       " 'data//doc1579.txt',\n",
       " 'data//doc158.txt',\n",
       " 'data//doc1580.txt',\n",
       " 'data//doc1581.txt',\n",
       " 'data//doc1582.txt',\n",
       " 'data//doc1583.txt',\n",
       " 'data//doc1584.txt',\n",
       " 'data//doc1585.txt',\n",
       " 'data//doc1586.txt',\n",
       " 'data//doc1587.txt',\n",
       " 'data//doc1588.txt',\n",
       " 'data//doc1589.txt',\n",
       " 'data//doc159.txt',\n",
       " 'data//doc1590.txt',\n",
       " 'data//doc1591.txt',\n",
       " 'data//doc1592.txt',\n",
       " 'data//doc1593.txt',\n",
       " 'data//doc1594.txt',\n",
       " 'data//doc1595.txt',\n",
       " 'data//doc1596.txt',\n",
       " 'data//doc1597.txt',\n",
       " 'data//doc1598.txt',\n",
       " 'data//doc1599.txt',\n",
       " 'data//doc16.txt',\n",
       " 'data//doc160.txt',\n",
       " 'data//doc1600.txt',\n",
       " 'data//doc1601.txt',\n",
       " 'data//doc1602.txt',\n",
       " 'data//doc1603.txt',\n",
       " 'data//doc1604.txt',\n",
       " 'data//doc1605.txt',\n",
       " 'data//doc1606.txt',\n",
       " 'data//doc1607.txt',\n",
       " 'data//doc1608.txt',\n",
       " 'data//doc1609.txt',\n",
       " 'data//doc161.txt',\n",
       " 'data//doc1610.txt',\n",
       " 'data//doc1611.txt',\n",
       " 'data//doc1612.txt',\n",
       " 'data//doc1613.txt',\n",
       " 'data//doc1614.txt',\n",
       " 'data//doc1615.txt',\n",
       " 'data//doc1616.txt',\n",
       " 'data//doc1617.txt',\n",
       " 'data//doc1618.txt',\n",
       " 'data//doc1619.txt',\n",
       " 'data//doc162.txt',\n",
       " 'data//doc1620.txt',\n",
       " 'data//doc1621.txt',\n",
       " 'data//doc1622.txt',\n",
       " 'data//doc1623.txt',\n",
       " 'data//doc1624.txt',\n",
       " 'data//doc1625.txt',\n",
       " 'data//doc1626.txt',\n",
       " 'data//doc1627.txt',\n",
       " 'data//doc1628.txt',\n",
       " 'data//doc1629.txt',\n",
       " 'data//doc163.txt',\n",
       " 'data//doc1630.txt',\n",
       " 'data//doc1631.txt',\n",
       " 'data//doc1632.txt',\n",
       " 'data//doc1633.txt',\n",
       " 'data//doc1634.txt',\n",
       " 'data//doc1635.txt',\n",
       " 'data//doc1636.txt',\n",
       " 'data//doc1637.txt',\n",
       " 'data//doc1638.txt',\n",
       " 'data//doc1639.txt',\n",
       " 'data//doc164.txt',\n",
       " 'data//doc1640.txt',\n",
       " 'data//doc1641.txt',\n",
       " 'data//doc1642.txt',\n",
       " 'data//doc1643.txt',\n",
       " 'data//doc1644.txt',\n",
       " 'data//doc1645.txt',\n",
       " 'data//doc1646.txt',\n",
       " 'data//doc1647.txt',\n",
       " 'data//doc1648.txt',\n",
       " 'data//doc1649.txt',\n",
       " 'data//doc165.txt',\n",
       " 'data//doc1650.txt',\n",
       " 'data//doc1651.txt',\n",
       " 'data//doc1652.txt',\n",
       " 'data//doc1653.txt',\n",
       " 'data//doc1654.txt',\n",
       " 'data//doc1655.txt',\n",
       " 'data//doc1656.txt',\n",
       " 'data//doc1657.txt',\n",
       " 'data//doc1658.txt',\n",
       " 'data//doc1659.txt',\n",
       " 'data//doc166.txt',\n",
       " 'data//doc1660.txt',\n",
       " 'data//doc1661.txt',\n",
       " 'data//doc1662.txt',\n",
       " 'data//doc1663.txt',\n",
       " 'data//doc1664.txt',\n",
       " 'data//doc1665.txt',\n",
       " 'data//doc1666.txt',\n",
       " 'data//doc1667.txt',\n",
       " 'data//doc1668.txt',\n",
       " 'data//doc1669.txt',\n",
       " 'data//doc167.txt',\n",
       " 'data//doc1670.txt',\n",
       " 'data//doc1671.txt',\n",
       " 'data//doc1672.txt',\n",
       " 'data//doc1673.txt',\n",
       " 'data//doc1674.txt',\n",
       " 'data//doc1675.txt',\n",
       " 'data//doc1676.txt',\n",
       " 'data//doc1677.txt',\n",
       " 'data//doc1678.txt',\n",
       " 'data//doc1679.txt',\n",
       " 'data//doc168.txt',\n",
       " 'data//doc1680.txt',\n",
       " 'data//doc1681.txt',\n",
       " 'data//doc1682.txt',\n",
       " 'data//doc1683.txt',\n",
       " 'data//doc1684.txt',\n",
       " 'data//doc1685.txt',\n",
       " 'data//doc1686.txt',\n",
       " 'data//doc1687.txt',\n",
       " 'data//doc1688.txt',\n",
       " 'data//doc1689.txt',\n",
       " 'data//doc169.txt',\n",
       " 'data//doc1690.txt',\n",
       " 'data//doc1691.txt',\n",
       " 'data//doc1692.txt',\n",
       " 'data//doc1693.txt',\n",
       " 'data//doc1694.txt',\n",
       " 'data//doc1695.txt',\n",
       " 'data//doc1696.txt',\n",
       " 'data//doc1697.txt',\n",
       " 'data//doc1698.txt',\n",
       " 'data//doc1699.txt',\n",
       " 'data//doc17.txt',\n",
       " 'data//doc170.txt',\n",
       " 'data//doc1700.txt',\n",
       " 'data//doc1701.txt',\n",
       " 'data//doc1702.txt',\n",
       " 'data//doc1703.txt',\n",
       " 'data//doc1704.txt',\n",
       " 'data//doc1705.txt',\n",
       " 'data//doc1706.txt',\n",
       " 'data//doc1707.txt',\n",
       " 'data//doc1708.txt',\n",
       " 'data//doc1709.txt',\n",
       " 'data//doc171.txt',\n",
       " 'data//doc1710.txt',\n",
       " 'data//doc1711.txt',\n",
       " 'data//doc1712.txt',\n",
       " 'data//doc1713.txt',\n",
       " 'data//doc1714.txt',\n",
       " 'data//doc1715.txt',\n",
       " 'data//doc1716.txt',\n",
       " 'data//doc1717.txt',\n",
       " 'data//doc1718.txt',\n",
       " 'data//doc1719.txt',\n",
       " 'data//doc172.txt',\n",
       " 'data//doc1720.txt',\n",
       " 'data//doc1721.txt',\n",
       " 'data//doc1722.txt',\n",
       " 'data//doc1723.txt',\n",
       " 'data//doc1724.txt',\n",
       " 'data//doc1725.txt',\n",
       " 'data//doc1726.txt',\n",
       " 'data//doc1727.txt',\n",
       " 'data//doc1728.txt',\n",
       " 'data//doc1729.txt',\n",
       " 'data//doc173.txt',\n",
       " 'data//doc1730.txt',\n",
       " 'data//doc1731.txt',\n",
       " 'data//doc1732.txt',\n",
       " 'data//doc1733.txt',\n",
       " 'data//doc1734.txt',\n",
       " 'data//doc1735.txt',\n",
       " 'data//doc1736.txt',\n",
       " 'data//doc1737.txt',\n",
       " 'data//doc1738.txt',\n",
       " 'data//doc1739.txt',\n",
       " 'data//doc174.txt',\n",
       " 'data//doc1740.txt',\n",
       " 'data//doc1741.txt',\n",
       " 'data//doc1742.txt',\n",
       " 'data//doc1743.txt',\n",
       " 'data//doc1744.txt',\n",
       " 'data//doc1745.txt',\n",
       " 'data//doc1746.txt',\n",
       " 'data//doc1747.txt',\n",
       " 'data//doc1748.txt',\n",
       " 'data//doc1749.txt',\n",
       " 'data//doc175.txt',\n",
       " 'data//doc1750.txt',\n",
       " 'data//doc1751.txt',\n",
       " 'data//doc1752.txt',\n",
       " 'data//doc1753.txt',\n",
       " 'data//doc1754.txt',\n",
       " 'data//doc1755.txt',\n",
       " 'data//doc1756.txt',\n",
       " 'data//doc1757.txt',\n",
       " 'data//doc1758.txt',\n",
       " 'data//doc1759.txt',\n",
       " 'data//doc176.txt',\n",
       " 'data//doc1760.txt',\n",
       " 'data//doc1761.txt',\n",
       " 'data//doc1762.txt',\n",
       " 'data//doc1763.txt',\n",
       " 'data//doc1764.txt',\n",
       " 'data//doc1765.txt',\n",
       " 'data//doc1766.txt',\n",
       " 'data//doc1767.txt',\n",
       " 'data//doc1768.txt',\n",
       " 'data//doc1769.txt',\n",
       " 'data//doc177.txt',\n",
       " 'data//doc1770.txt',\n",
       " 'data//doc1771.txt',\n",
       " 'data//doc1772.txt',\n",
       " 'data//doc1773.txt',\n",
       " 'data//doc1774.txt',\n",
       " 'data//doc1775.txt',\n",
       " 'data//doc1776.txt',\n",
       " 'data//doc1777.txt',\n",
       " 'data//doc1778.txt',\n",
       " 'data//doc1779.txt',\n",
       " 'data//doc178.txt',\n",
       " 'data//doc1780.txt',\n",
       " 'data//doc1781.txt',\n",
       " 'data//doc1782.txt',\n",
       " 'data//doc1783.txt',\n",
       " 'data//doc1784.txt',\n",
       " 'data//doc1785.txt',\n",
       " 'data//doc1786.txt',\n",
       " 'data//doc1787.txt',\n",
       " 'data//doc1788.txt',\n",
       " 'data//doc1789.txt',\n",
       " 'data//doc179.txt',\n",
       " 'data//doc1790.txt',\n",
       " 'data//doc1791.txt',\n",
       " 'data//doc1792.txt',\n",
       " 'data//doc1793.txt',\n",
       " 'data//doc1794.txt',\n",
       " 'data//doc1795.txt',\n",
       " 'data//doc1796.txt',\n",
       " 'data//doc1797.txt',\n",
       " 'data//doc1798.txt',\n",
       " 'data//doc1799.txt',\n",
       " 'data//doc18.txt',\n",
       " 'data//doc180.txt',\n",
       " 'data//doc1800.txt',\n",
       " 'data//doc1801.txt',\n",
       " 'data//doc1802.txt',\n",
       " 'data//doc1803.txt',\n",
       " 'data//doc1804.txt',\n",
       " 'data//doc1805.txt',\n",
       " 'data//doc1806.txt',\n",
       " 'data//doc1807.txt',\n",
       " 'data//doc1808.txt',\n",
       " 'data//doc1809.txt',\n",
       " 'data//doc181.txt',\n",
       " 'data//doc1810.txt',\n",
       " 'data//doc1811.txt',\n",
       " 'data//doc1812.txt',\n",
       " 'data//doc1813.txt',\n",
       " 'data//doc1814.txt',\n",
       " 'data//doc1815.txt',\n",
       " 'data//doc1816.txt',\n",
       " 'data//doc1817.txt',\n",
       " 'data//doc1818.txt',\n",
       " 'data//doc1819.txt',\n",
       " 'data//doc182.txt',\n",
       " 'data//doc1820.txt',\n",
       " 'data//doc1821.txt',\n",
       " 'data//doc1822.txt',\n",
       " 'data//doc1823.txt',\n",
       " 'data//doc1824.txt',\n",
       " 'data//doc1825.txt',\n",
       " 'data//doc1826.txt',\n",
       " 'data//doc1827.txt',\n",
       " 'data//doc1828.txt',\n",
       " 'data//doc1829.txt',\n",
       " 'data//doc183.txt',\n",
       " 'data//doc1830.txt',\n",
       " 'data//doc1831.txt',\n",
       " 'data//doc1832.txt',\n",
       " 'data//doc1833.txt',\n",
       " 'data//doc1834.txt',\n",
       " 'data//doc1835.txt',\n",
       " 'data//doc1836.txt',\n",
       " 'data//doc1837.txt',\n",
       " 'data//doc1838.txt',\n",
       " 'data//doc1839.txt',\n",
       " 'data//doc184.txt',\n",
       " 'data//doc1840.txt',\n",
       " 'data//doc1841.txt',\n",
       " 'data//doc1842.txt',\n",
       " 'data//doc1843.txt',\n",
       " 'data//doc1844.txt',\n",
       " 'data//doc1845.txt',\n",
       " 'data//doc1846.txt',\n",
       " 'data//doc1847.txt',\n",
       " 'data//doc1848.txt',\n",
       " 'data//doc1849.txt',\n",
       " 'data//doc185.txt',\n",
       " 'data//doc1850.txt',\n",
       " 'data//doc1851.txt',\n",
       " 'data//doc1852.txt',\n",
       " 'data//doc1853.txt',\n",
       " 'data//doc1854.txt',\n",
       " 'data//doc1855.txt',\n",
       " 'data//doc1856.txt',\n",
       " 'data//doc1857.txt',\n",
       " 'data//doc1858.txt',\n",
       " 'data//doc1859.txt',\n",
       " 'data//doc186.txt',\n",
       " 'data//doc1860.txt',\n",
       " 'data//doc1861.txt',\n",
       " 'data//doc1862.txt',\n",
       " 'data//doc1863.txt',\n",
       " 'data//doc1864.txt',\n",
       " 'data//doc1865.txt',\n",
       " 'data//doc1866.txt',\n",
       " 'data//doc1867.txt',\n",
       " 'data//doc1868.txt',\n",
       " 'data//doc1869.txt',\n",
       " 'data//doc187.txt',\n",
       " 'data//doc1870.txt',\n",
       " 'data//doc1871.txt',\n",
       " 'data//doc1872.txt',\n",
       " 'data//doc1873.txt',\n",
       " 'data//doc1874.txt',\n",
       " 'data//doc1875.txt',\n",
       " 'data//doc1876.txt',\n",
       " 'data//doc1877.txt',\n",
       " 'data//doc1878.txt',\n",
       " 'data//doc1879.txt',\n",
       " 'data//doc188.txt',\n",
       " 'data//doc1880.txt',\n",
       " 'data//doc1881.txt',\n",
       " 'data//doc1882.txt',\n",
       " 'data//doc1883.txt',\n",
       " 'data//doc1884.txt',\n",
       " 'data//doc1885.txt',\n",
       " 'data//doc1886.txt',\n",
       " 'data//doc1887.txt',\n",
       " 'data//doc1888.txt',\n",
       " 'data//doc1889.txt',\n",
       " 'data//doc189.txt',\n",
       " 'data//doc1890.txt',\n",
       " 'data//doc1891.txt',\n",
       " 'data//doc1892.txt',\n",
       " 'data//doc1893.txt',\n",
       " 'data//doc1894.txt',\n",
       " 'data//doc1895.txt',\n",
       " 'data//doc1896.txt',\n",
       " 'data//doc1897.txt',\n",
       " 'data//doc1898.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_doc(fname):\n",
    "    #If you are using files that aren't plain text, you may have to change this\n",
    "    f = open(fname, 'r')\n",
    "    doc = []\n",
    "    for line in f:\n",
    "        if line[0] == \"%\":\n",
    "            continue\n",
    "        phrases = line.split()\n",
    "        for phrase in phrases:\n",
    "            p1 = phrase[-1]\n",
    "            \n",
    "            phrase = phrase.lower()\n",
    "            \n",
    "            if phrase not in word_index:\n",
    "                n_words = word_index[\"n_words\"]\n",
    "                word_index[phrase] = n_words\n",
    "                word_index[n_words] = phrase\n",
    "                word_index[\"n_words\"] += 1\n",
    "            ind = word_index[phrase]\n",
    "            doc.append(ind)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_doc('data/doc0.txt')\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_docs():\n",
    "    #turn each document into a list of words\n",
    "    docs = []\n",
    "    fnames = get_fnames()\n",
    "    for fname in fnames:\n",
    "        docs.append(read_doc(fname))\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = read_docs()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_choice(probs):\n",
    "    #given a list of probabilities, randomly return an index i according to\n",
    "    #that index's probability.\n",
    "    partials = []\n",
    "    psum = 0.\n",
    "    for p in probs:\n",
    "        psum += p\n",
    "        partials.append(psum)\n",
    "\n",
    "    choice = random.random()*psum\n",
    "    #bisect_right does binary search to find minimal k where partials[k]>choice\n",
    "    return bisect.bisect_right(partials, choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 1, 0, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random_choice([0.3,0.5,0.2]) for _ in range(25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probs(v, nkm, nkr, nk, n_topics):\n",
    "    #get something proportional to the\n",
    "    #probability for word n to be in\n",
    "    #each topic k\n",
    "    #given that there are n_topics topics. The word is vth from vocabulary.\n",
    "    #nkm is number of words from this document in kth topic\n",
    "    #nkr is number of times rth word from vocab appears in kth topic\n",
    "    #nk is number of words in kth topic\n",
    "    n_words = word_index[\"n_words\"]\n",
    "    res = [0]*n_topics   #a probability to be in each topic\n",
    "\n",
    "    for k in range(n_topics):\n",
    "        res[k] = (nkm[k]+alpha)*(nkr[k][v]+beta)/(nk[k]+n_words*beta)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_topics(iters, w_counts, docs, n_topics):\n",
    "    #returns total number of words in each topic and relative distribution of\n",
    "    #words in topic compared to distribution across all documents\n",
    "    n_words = word_index[\"n_words\"]\n",
    "    zs = []\n",
    "    nkr = [[0]*n_words for _ in range(n_topics)] #(k,r)th element is number of\n",
    "    #times rth word from vocab appears in topic k\n",
    "    nkm = [[0]*n_topics for _ in range(len(docs))]\n",
    "    #(m,k)th element is number of words in document m are in kth topic\n",
    "    nk  = [0]*n_topics #number of words in each topic\n",
    "\n",
    "    n_words_total = 0 #number of words in all documents, INCLUDING repetition\n",
    "    for i in range(len(docs)):\n",
    "        zs.append([])\n",
    "        for j in range(len(docs[i])):\n",
    "            topic = random.randint(0,n_topics-1)\n",
    "            zs[i].append(topic)\n",
    "            ind = docs[i][j]\n",
    "            nkm[i][topic] += 1\n",
    "            nkr[topic][ind] += 1\n",
    "            nk[topic] += 1\n",
    "            n_words_total += 1\n",
    "    for it in range(iters):\n",
    "        print (\"Iteration\",it)\n",
    "        for i in range(len(docs)):\n",
    "            for j in range(len(docs[i])):\n",
    "                ind = docs[i][j]\n",
    "                k = zs[i][j]\n",
    "                nkm[i][k] -= 1\n",
    "                nkr[k][ind] -= 1\n",
    "                nk[k] -= 1\n",
    "                ps = probs(ind, nkm[i], nkr, nk, n_topics)\n",
    "                newk = random_choice(ps)\n",
    "                nkm[i][newk] += 1\n",
    "                nkr[newk][ind] += 1\n",
    "                nk[newk] += 1\n",
    "                zs[i][j] = newk\n",
    "\n",
    "    for k in range(n_topics):\n",
    "        for v in range(n_words):\n",
    "            nkr[k][v] /= nk[k]+0.\n",
    "            nkr[k][v] -= (w_counts[v]+ 0.)/n_words_total\n",
    "    return [[nk[k],nkr[k]] for k in range(n_topics)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_topics(topics):\n",
    "    #take output of topics and make it look pretty\n",
    "    relevant = 10\t#I only care about 10 most frequent words in topic\n",
    "    n_words = word_index[\"n_words\"]\n",
    "    for nk,t in topics:\n",
    "        top = [[-1,0]]*relevant\n",
    "        for i in range(n_words):\n",
    "            for j in range(relevant):\n",
    "                if t[i] > top[j][1]:\n",
    "                    top[j+1:] = top[j:-1]\n",
    "                    top[j] = [word_index[i],t[i]]\n",
    "                    break\n",
    "        print (\"\\n\"+\"==TOPIC==\", \" with number of words =\", nk)\n",
    "        for rank in top:\n",
    "            print (rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = read_docs()\n",
    "n_topics = 12 #number of topics\n",
    "n_words = word_index[\"n_words\"]\n",
    "w_counts = [0]*n_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "\n",
      "==TOPIC==  with number of words = 7695\n",
      "['vinci', 0.09089181838868673]\n",
      "['code', 0.0902290186996749]\n",
      "['da', 0.08855263710213704]\n",
      "['awesome', 0.047306751783209394]\n",
      "['was', 0.030813972479719245]\n",
      "['left', 0.017850495288753074]\n",
      "['movie', 0.017220176187295537]\n",
      "['up', 0.017148297693269674]\n",
      "['right', 0.015989518111817074]\n",
      "['down', 0.014778630092705702]\n",
      "\n",
      "==TOPIC==  with number of words = 8127\n",
      "['potter', 0.03745678983385861]\n",
      "['harry', 0.03290406435090057]\n",
      "['i', 0.026089390582155834]\n",
      "['to', 0.021589267242984253]\n",
      "['think', 0.020501291217046053]\n",
      "['reading', 0.01892916099463646]\n",
      "['it', 0.017301580200554362]\n",
      "['one', 0.01710820929563971]\n",
      "['story', 0.016475452760618]\n",
      "['is', 0.01588231774528528]\n",
      "\n",
      "==TOPIC==  with number of words = 6587\n",
      "['like', 0.06625496874115727]\n",
      "['sucks', 0.03087029589066726]\n",
      "['i', 0.02665545740628559]\n",
      "['would', 0.02512045967536993]\n",
      "['this', 0.024842379244129457]\n",
      "['a', 0.022623123048804962]\n",
      "['and', 0.02203828553739232]\n",
      "['harry', 0.02177023995557801]\n",
      "['potter', 0.02131479741724493]\n",
      "['be', 0.017172495033061022]\n",
      "\n",
      "==TOPIC==  with number of words = 5702\n",
      "['and', 0.03998590586477313]\n",
      "['his', 0.02902155994832894]\n",
      "['s', 0.019824263060281483]\n",
      "['making', 0.01428679571138785]\n",
      "['got', 0.013857878933538771]\n",
      "['around', 0.013799745857590537]\n",
      "['cock', 0.013799745857590537]\n",
      "['hard', 0.013637395906324765]\n",
      "['he', 0.01363039343519954]\n",
      "['him', 0.013448991736229612]\n",
      "\n",
      "==TOPIC==  with number of words = 6063\n",
      "['the', 0.03890499708980649]\n",
      "['a', 0.03528396989649232]\n",
      "['love', 0.031458191694673496]\n",
      "['for', 0.03034224133005313]\n",
      "['in', 0.022942260905310104]\n",
      "['book', 0.02015162115780389]\n",
      "['have', 0.019088266968569016]\n",
      "['also', 0.01792511347567364]\n",
      "['which', 0.01733402476924263]\n",
      "['then', 0.016406036062480953]\n",
      "\n",
      "==TOPIC==  with number of words = 5528\n",
      "['brokeback', 0.03400366829073183]\n",
      "['mountain', 0.033641873790008235]\n",
      "['a', 0.027319448552466624]\n",
      "['fucking', 0.025048767766474567]\n",
      "['movies', 0.023271151760300885]\n",
      "['horrible', 0.022605913745868397]\n",
      "['hate', 0.021594788066556955]\n",
      "['on', 0.019111141849140305]\n",
      "['harry', 0.019043956087669088]\n",
      "['you', 0.017757491327875886]\n",
      "\n",
      "==TOPIC==  with number of words = 6764\n",
      "['code', 0.11466484818182807]\n",
      "['vinci', 0.11112967895771231]\n",
      "['da', 0.10654659202690214]\n",
      "['the', 0.06663077958667825]\n",
      "['sucked', 0.03402288278406477]\n",
      "['sucks', 0.021282458370084585]\n",
      "['know', 0.017398012774933542]\n",
      "['awesome', 0.01385185987178289]\n",
      "['by', 0.013294517606099855]\n",
      "['way', 0.012877047283237932]\n",
      "\n",
      "==TOPIC==  with number of words = 7757\n",
      "['i', 0.05656120677189822]\n",
      "['it', 0.03454335306890308]\n",
      "['harry', 0.027265650996725607]\n",
      "['but', 0.026838967399731743]\n",
      "['potter', 0.024429503001366572]\n",
      "['want', 0.02440801507240422]\n",
      "['because', 0.023277145424816615]\n",
      "['not', 0.02101222702455929]\n",
      "['much', 0.016543098871489744]\n",
      "['of', 0.015734588463948637]\n",
      "\n",
      "==TOPIC==  with number of words = 5964\n",
      "['and', 0.06432726560982123]\n",
      "['my', 0.05417597578575772]\n",
      "['stupid', 0.03934302592212167]\n",
      "['s', 0.03380355562850504]\n",
      "['she', 0.026444396483246625]\n",
      "['at', 0.017011015281620637]\n",
      "['went', 0.016945879734547177]\n",
      "['saw', 0.016224760204859554]\n",
      "['with', 0.015027535211573406]\n",
      "['me', 0.014663186794603541]\n",
      "\n",
      "==TOPIC==  with number of words = 4956\n",
      "['mission', 0.08885568693309534]\n",
      "['impossible', 0.08503497715792568]\n",
      "['was', 0.053082056374327086]\n",
      "['which', 0.02093024348803031]\n",
      "['i', 0.020322361657854553]\n",
      "['said', 0.01755361199634648]\n",
      "['why', 0.017253410198115417]\n",
      "['turned', 0.015288629803269515]\n",
      "['hill', 0.015288629803269515]\n",
      "['reality', 0.015288629803269515]\n",
      "\n",
      "==TOPIC==  with number of words = 6695\n",
      "['mountain', 0.10807572889279679]\n",
      "['brokeback', 0.10374413815343905]\n",
      "['was', 0.027547931128172873]\n",
      "['loved', 0.026388734373707413]\n",
      "['movie', 0.024751229638975795]\n",
      "['i', 0.02448822212616688]\n",
      "['love', 0.023653533683206402]\n",
      "['beautiful', 0.014463971369079249]\n",
      "['watch', 0.012640360901716084]\n",
      "['re', 0.012134089875983377]\n",
      "\n",
      "==TOPIC==  with number of words = 4925\n",
      "['impossible', 0.0403806587498432]\n",
      "['mission', 0.039352403214032564]\n",
      "['so', 0.03625092223007449]\n",
      "['felicia', 0.030402972138319335]\n",
      "['as', 0.028355943744312627]\n",
      "['is', 0.022432296227739266]\n",
      "['suck', 0.018536497496976487]\n",
      "['me', 0.018341976963706142]\n",
      "['we', 0.018020801185744693]\n",
      "['and', 0.017015748452733185]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Number of iterations should probably be about 10 for decent convergence\n",
    "#each iteration iterates over all meaningful words in each document, so this\n",
    "#could be expensive for large document sets\n",
    "iters = 10\n",
    "for doc in docs:\n",
    "    for word in doc:\n",
    "        w_counts[word] += 1\n",
    "topics = get_topics(iters, w_counts, docs , n_topics)\n",
    "display_topics(topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
